# -*- coding: utf-8 -*-
"""only-emotion.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15DVw9bPiOi3CbnTyhrEQstIzoEE7rjOX
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, log_loss, roc_auc_score

# Step 1: Load Dataset
uploaded ="/content/text.csv"  # Update the correct path
df = pd.read_csv(uploaded)

# Step 2: Data Preprocessing
df.dropna(inplace=True)  # Remove any missing values
texts = df['text'].astype(str).values
emotions = df['label'].values

# Step 3: Encode Emotion Labels
emotion_encoder = LabelEncoder()
emotions_encoded = emotion_encoder.fit_transform(emotions)

# Step 4: Tokenization & Padding
vocab_size = 10000  # Adjust based on dataset
max_length = 100  # Truncate or pad to 100 words
oov_token = "<OOV>"

tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)
tokenizer.fit_on_texts(texts)
sequences = tokenizer.texts_to_sequences(texts)
padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')

# Step 5: Train-Test Split
X_train, X_test, y_train_emotion, y_test_emotion = train_test_split(padded_sequences, emotions_encoded, test_size=0.2, random_state=42)

# Step 6: Build Bi-LSTM Model for Emotion Classification
def build_lstm_model(output_dim):
    model = Sequential([
        Embedding(input_dim=vocab_size, output_dim=128, input_length=max_length),
        Bidirectional(LSTM(64, return_sequences=True)),
        Dropout(0.3),
        Bidirectional(LSTM(32)),
        Dense(64, activation='relu'),
        Dropout(0.3),
        Dense(output_dim, activation='softmax')  # Softmax for multi-class classification
    ])
    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# Step 7: Train Emotion Model
model_emotion = build_lstm_model(len(emotion_encoder.classes_))
model_emotion.fit(X_train, y_train_emotion, epochs=5, batch_size=64, validation_data=(X_test, y_test_emotion))

# Step 8: Evaluate the Emotion Model
emotion_loss, emotion_acc = model_emotion.evaluate(X_test, y_test_emotion)

# Predictions for metrics computation
y_pred_emotion = model_emotion.predict(X_test)

# Convert softmax outputs to class predictions
y_pred_emotion_classes = np.argmax(y_pred_emotion, axis=1)

# Compute Classification Scores
def compute_metrics(y_true, y_pred_probs, y_pred_classes, label_encoder):
    report = classification_report(y_true, y_pred_classes, target_names=label_encoder.classes_, output_dict=True)
    logloss = log_loss(y_true, y_pred_probs)
    auc_roc = roc_auc_score(y_true, y_pred_probs, multi_class='ovr')
    return report, logloss, auc_roc

# Emotion Scores
emotion_report, emotion_logloss, emotion_auc = compute_metrics(y_test_emotion, y_pred_emotion, y_pred_emotion_classes, emotion_encoder)

# Print Emotion Model Results
print(f"\nEmotion Model Scores:")
print(f"Accuracy: {emotion_acc:.4f}")
print(f"Log Loss: {emotion_logloss:.4f}")
print(f"AUC-ROC: {emotion_auc:.4f}")
print(f"Classification Report:")
print(pd.DataFrame(emotion_report).T)

# Step 9: Save the Emotion Model
model_emotion.save("emotion_model.h5")

# Emotion index-to-label mapping
emotion_labels = {
    0: 'sadness',
    1: 'joy',
    2: 'love',
    3: 'anger',
    4: 'fear',
    5: 'surprise'
}

def predict_emotion(text):
    # Step 1: Tokenize and pad input text
    sequence = tokenizer.texts_to_sequences([text])
    padded = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')

    # Step 2: Predict using the trained model
    pred_probs = model_emotion.predict(padded)
    pred_class = np.argmax(pred_probs, axis=1)[0]

    # Step 3: Map predicted class to emotion label
    predicted_emotion = emotion_labels.get(pred_class, "Unknown")

    return predicted_emotion

sample_text = "I dont know how it is going in this mood"
predicted_emotion = predict_emotion(sample_text)
print(f"Predicted Emotion: {predicted_emotion}")